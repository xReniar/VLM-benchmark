{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5094054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rainer/anaconda3/envs/vlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor\n",
    "from PIL import Image\n",
    "import io\n",
    "from json2xml import json2xml\n",
    "from json2xml.utils import readfromurl, readfromstring, readfromjson\n",
    "import json\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfcfff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2413cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "model_id = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "633ac20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = load_dataset(\"nanonets/key_information_extraction\",\n",
    "                                                split=[\"test\"])[0]\n",
    "                                                \n",
    "system_message = \"\"\"You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \n",
    "Your task is to process and extract meaningful insights from images, videos, and visual patterns, \n",
    "leveraging multimodal understanding to provide accurate and contextually relevant information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ecff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample: dict):\n",
    "    image_buffer = io.BytesIO(sample[\"image\"])\n",
    "    pil_image = Image.open(image_buffer)\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"image\", \"image\": pil_image },\n",
    "                { \"type\": \"text\", \"text\": \"Perform key information extraction\" }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{ \"type\": \"text\", \"text\": sample[\"annotations\"]}]\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b74fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = [format_data(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa69a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \\nYour task is to process and extract meaningful insights from images, videos, and visual patterns, \\nleveraging multimodal understanding to provide accurate and contextually relevant information.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=928x2110>},\n",
       "   {'type': 'text', 'text': 'Perform key information extraction'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': {'date': '20/04/2018',\n",
       "     'doc_no_receipt_no': 'CS00012013',\n",
       "     'seller_address': 'LOT 276 JALAN BANTING \\n43800 DENGKIL , SELANGOR .',\n",
       "     'seller_gst_id': '000781500416',\n",
       "     'seller_name': 'KEDAI PAPAN YEW CHUAN',\n",
       "     'seller_phone': '03-87686092 ',\n",
       "     'total_amount': '87.45',\n",
       "     'total_tax': '4.95'}}]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generator(sample_data):\n",
    "    text = processor.apply_chat_template(\n",
    "        sample_data[0:2], tokenize = False, add_generation_prompt = True\n",
    "    )\n",
    "\n",
    "    # json to xml\n",
    "    data = json2xml.Json2xml(\n",
    "        data=readfromstring(json.dumps(sample_data[2][\"content\"][0][\"text\"])),\n",
    "        wrapper=\"key-information-extraction\",\n",
    "        pretty=False,\n",
    "        attr_type=False\n",
    "    ).to_xml()\n",
    "    data = etree.tostring(\n",
    "        etree.fromstring(data),\n",
    "        encoding=\"unicode\",\n",
    "        pretty_print=False\n",
    "    )\n",
    "\n",
    "    print(data)\n",
    "    print(\"#\" * 30)\n",
    "\n",
    "    image_inputs = sample_data[1][\"content\"][0][\"image\"]\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bed2379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \\nYour task is to process and extract meaningful insights from images, videos, and visual patterns, \\nleveraging multimodal understanding to provide accurate and contextually relevant information.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=928x2143>},\n",
       "   {'type': 'text', 'text': 'Perform key information extraction'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': {'date': '26/05/2018',\n",
       "     'doc_no_receipt_no': 'CS00013125',\n",
       "     'seller_address': 'LOT 276 JALAN BANTING \\n43800 DENGKIL , SELANGOR .',\n",
       "     'seller_gst_id': '000781500416',\n",
       "     'seller_name': 'KEDAI PAPAN YEW CHUAN',\n",
       "     'seller_phone': '03-87686092',\n",
       "     'total_amount': '121.90',\n",
       "     'total_tax': '6.90'}}]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c9117c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<key-information-extraction><date>26/05/2018</date><doc_no_receipt_no>CS00013125</doc_no_receipt_no><seller_address>LOT 276 JALAN BANTING \n",
      "43800 DENGKIL , SELANGOR .</seller_address><seller_gst_id>000781500416</seller_gst_id><seller_name>KEDAI PAPAN YEW CHUAN</seller_name><seller_phone>03-87686092</seller_phone><total_amount>121.90</total_amount><total_tax>6.90</total_tax></key-information-extraction>\n",
      "##############################\n",
      "<class 'transformers.feature_extraction_utils.BatchFeature'>\n",
      "<|im_start|>system\n",
      "You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \n",
      "Your task is to process and extract meaningful insights from images, videos, and visual patterns, \n",
      "leveraging multimodal understanding to provide accurate and contextually relevant information.<|im_end|>\n",
      "<|im_start|>user\n",
      "<|vision_start|><|image_pad|><|vision_end|>Perform key information extraction<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text_generator(test_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bea5b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<key-information-extraction><date>26/05/2018</date><doc_no_receipt_no>CS00013125</doc_no_receipt_no><seller_address>LOT 276 JALAN BANTING \n",
      "43800 DENGKIL , SELANGOR .</seller_address><seller_gst_id>000781500416</seller_gst_id><seller_name>KEDAI PAPAN YEW CHUAN</seller_name><seller_phone>03-87686092</seller_phone><total_amount>121.90</total_amount><total_tax>6.90</total_tax></key-information-extraction>\n",
      "##############################\n",
      "<class 'transformers.feature_extraction_utils.BatchFeature'>\n",
      "<|im_start|>System: You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \n",
      "Your task is to process and extract meaningful insights from images, videos, and visual patterns, \n",
      "leveraging multimodal understanding to provide accurate and contextually relevant information.<end_of_utterance>\n",
      "User:<image>Perform key information extraction<end_of_utterance>\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "print(text_generator(test_dataset[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
