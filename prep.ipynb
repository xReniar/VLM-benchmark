{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5094054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2413cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "model_id = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "633ac20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = load_dataset(\"nanonets/key_information_extraction\",\n",
    "                                                split=[\"test[:1%]\"])[0]\n",
    "                                                \n",
    "system_message = \"\"\"You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \n",
    "Your task is to process and extract meaningful insights from images, videos, and visual patterns, \n",
    "leveraging multimodal understanding to provide accurate and contextually relevant information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52ecff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample: dict):\n",
    "    image_buffer = io.BytesIO(sample[\"image\"])\n",
    "    pil_image = Image.open(image_buffer)\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": pil_image,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Perform key information extraction\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": sample[\"annotations\"]}],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b74fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = [format_data(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fa69a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \\nYour task is to process and extract meaningful insights from images, videos, and visual patterns, \\nleveraging multimodal understanding to provide accurate and contextually relevant information.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=928x2143>},\n",
       "   {'type': 'text', 'text': 'Perform key information extraction'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': {'date': '26/05/2018',\n",
       "     'doc_no_receipt_no': 'CS00013125',\n",
       "     'seller_address': 'LOT 276 JALAN BANTING \\n43800 DENGKIL , SELANGOR .',\n",
       "     'seller_gst_id': '000781500416',\n",
       "     'seller_name': 'KEDAI PAPAN YEW CHUAN',\n",
       "     'seller_phone': '03-87686092',\n",
       "     'total_amount': '121.90',\n",
       "     'total_tax': '6.90'}}]}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c053b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generator(sample_data):\n",
    "    text = processor.apply_chat_template(\n",
    "        sample_data[0:2], tokenize = False, add_generation_prompt = True\n",
    "    )\n",
    "\n",
    "    #print(f\"Prompt: {text}\")\n",
    "\n",
    "    image_inputs = sample_data[1][\"content\"][0][\"image\"]\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    #print(inputs)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bed2379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \\nYour task is to process and extract meaningful insights from images, videos, and visual patterns, \\nleveraging multimodal understanding to provide accurate and contextually relevant information.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=928x2143>},\n",
       "   {'type': 'text', 'text': 'Perform key information extraction'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': {'date': '26/05/2018',\n",
       "     'doc_no_receipt_no': 'CS00013125',\n",
       "     'seller_address': 'LOT 276 JALAN BANTING \\n43800 DENGKIL , SELANGOR .',\n",
       "     'seller_gst_id': '000781500416',\n",
       "     'seller_name': 'KEDAI PAPAN YEW CHUAN',\n",
       "     'seller_phone': '03-87686092',\n",
       "     'total_amount': '121.90',\n",
       "     'total_tax': '6.90'}}]}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5476e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>System: You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data. \n",
      "Your task is to process and extract meaningful insights from images, videos, and visual patterns, \n",
      "leveraging multimodal understanding to provide accurate and contextually relevant information.<end_of_utterance>\n",
      "User:<image>Perform key information extraction<end_of_utterance>\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "print(text_generator(test_dataset[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
