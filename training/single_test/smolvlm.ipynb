{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7375c62e",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd367240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b49bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a highly advanced Vision Language Model (VLM), specialized in extracting visual data. \n",
    "Your task is to process and extract meaningful insights from images, \n",
    "leveraging multimodal understanding to provide accurate and contextually relevant information.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d58e0",
   "metadata": {},
   "source": [
    "### Read and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18d485d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sroie_data(split: str):\n",
    "    root_path = \"../../data/sroie\"\n",
    "    imgs_folder_path = f\"{root_path}/{split}/img\"\n",
    "    labels_folder_path = f\"../../data/sroie/{split}/entities\"\n",
    "\n",
    "    data = []\n",
    "    for label_fn in os.listdir(labels_folder_path):\n",
    "        with open(os.path.join(labels_folder_path, label_fn), \"r\") as f:\n",
    "            json_f: dict = json.load(f)\n",
    "\n",
    "        data.append(dict(\n",
    "            img_path = os.path.join(imgs_folder_path, label_fn.replace(\".txt\", \".jpg\")),\n",
    "            label = json_f\n",
    "        ))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ae853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path': '../../data/sroie/train/img/X51005447840.jpg',\n",
       " 'label': {'company': 'PASARAYA BORONG PINTAR SDN BHD',\n",
       "  'date': '14/03/2018',\n",
       "  'address': 'NO 19-G& 19-1& 19-2 JALAN TASIK UTAMA 4, MEDAN NIAGA TASIK DAMAI',\n",
       "  'total': '8.20'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = read_sroie_data(\"train\")\n",
    "test_dataset = read_sroie_data(\"test\")\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bd4ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample: dict):\n",
    "    pil_image = Image.open(sample[\"img_path\"])\n",
    "\n",
    "    field_names = list(sample[\"label\"].keys())\n",
    "    output_format = {field: \"..\" for field in field_names}\n",
    "\n",
    "    prompt = \"Extract the following {fields} from the above document. If a field is not present, return ''. Return the output in a valid JSON format like {output_format}\" \\\n",
    "        .format(\n",
    "            fields = field_names,\n",
    "            output_format = output_format\n",
    "        )\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"image\", \"image\": pil_image },\n",
    "                { \"type\": \"text\", \"text\": prompt }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{ \"type\": \"text\", \"text\": json.dumps(sample[\"label\"])}]\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [format_data(sample) for sample in train_dataset]\n",
    "test_dataset = [format_data(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "145e0382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a highly advanced Vision Language Model (VLM), specialized in extracting visual data. \\nYour task is to process and extract meaningful insights from images, \\nleveraging multimodal understanding to provide accurate and contextually relevant information.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=932x2160>},\n",
       "   {'type': 'text',\n",
       "    'text': \"Extract the following ['company', 'date', 'address', 'total'] from the above document. If a field is not present, return ''. Return the output in a valid JSON format like {'company': '..', 'date': '..', 'address': '..', 'total': '..'}\"}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': '{\"company\": \"PASARAYA BORONG PINTAR SDN BHD\", \"date\": \"14/03/2018\", \"address\": \"NO 19-G& 19-1& 19-2 JALAN TASIK UTAMA 4, MEDAN NIAGA TASIK DAMAI\", \"total\": \"8.20\"}'}]}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2eb387",
   "metadata": {},
   "source": [
    "### Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "import torch\n",
    "from transformers import Idefics3ForConditionalGeneration, AutoProcessor\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_id = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"down_proj\", \"o_proj\", \"k_proj\", \"q_proj\", \"gate_proj\", \"up_proj\", \"v_proj\"],\n",
    "    use_dora=True,\n",
    "    init_lora_weights=\"gaussian\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_token_id = processor.tokenizer.additional_special_tokens_ids[\n",
    "    processor.tokenizer.additional_special_tokens.index(\"<image>\")\n",
    "]\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    texts = [processor.apply_chat_template(example, tokenize=False) for example in examples]\n",
    "\n",
    "    image_inputs = []\n",
    "    for example in examples:\n",
    "        image = example[1][\"content\"][0][\"image\"]\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        image_inputs.append([image])\n",
    "\n",
    "    batch = processor(text=texts, images=image_inputs, return_tensors=\"pt\", padding=True)\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100  # Mask padding tokens in labels\n",
    "    labels[labels == image_token_id] = -100  # Mask image token IDs in labels\n",
    "\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "# Configure training arguments using SFTConfig\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"smolvlm-instruct-trl-sft-sroie\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=50,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=25,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=25,\n",
    "    save_total_limit=1,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    bf16=True,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=True,\n",
    "    dataset_text_field=\"\",\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fe4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=processor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
