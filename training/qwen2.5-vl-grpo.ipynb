{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb2c2f9",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from dataset import *\n",
    "from PIL import Image\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastVisionModel\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a highly advanced Vision Language Model (VLM), specialized in extracting visual data.\n",
    "Your task is to process and extract meaningful insights from images that are asked in the prompt.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json2xml import json2xml\n",
    "from json2xml.utils import readfromstring\n",
    "from lxml import etree\n",
    "import base64\n",
    "\n",
    "\n",
    "def format_data(sample, train_type: str):\n",
    "    pil_image = Image.open(sample.image_path)\n",
    "\n",
    "    field_names = set([entity.label for entity in sample.entities])\n",
    "    if train_type == \"xml\":\n",
    "        xml_fields = \"\".join([f\"<{field}>..</{field}>\" for field in field_names])\n",
    "        output_format = f\"<kie>{xml_fields}</kie>\"\n",
    "        prompt = \"Extract the following {fields} from the above document. If a field is not present, return ''. Return the output in a valid XML format like {output_format}\" \\\n",
    "            .format(\n",
    "                fields = list(field_names),\n",
    "                output_format = output_format\n",
    "            )\n",
    "    else:\n",
    "        output_format = {field: \"..\" for field in field_names}\n",
    "\n",
    "        prompt = \"Extract the following {fields} from the above document. If a field is not present, return ''. Return the output in a valid JSON format like {output_format}\" \\\n",
    "            .format(\n",
    "                fields = list(field_names),\n",
    "                output_format = output_format\n",
    "            )\n",
    "\n",
    "    if train_type == \"normal\":\n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": system_message}]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    { \"type\": \"image\", \"image\": pil_image },\n",
    "                    { \"type\": \"text\", \"text\": prompt }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": json.dumps(sample.to_json(\"kie\"))\n",
    "                }]\n",
    "            }\n",
    "        ]\n",
    "    elif train_type == \"no-prompt\":\n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    { \"type\": \"image\", \"image\": pil_image }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": json.dumps(sample.to_json(\"kie\"))\n",
    "                }]\n",
    "            }\n",
    "        ]\n",
    "    elif train_type == \"xml\":\n",
    "        label = json2xml.Json2xml(\n",
    "            data=readfromstring(json.dumps(sample.to_json(\"kie\"))),\n",
    "            wrapper=\"kie\",\n",
    "            pretty=False,\n",
    "            attr_type=False\n",
    "        ).to_xml()\n",
    "        label = etree.tostring(\n",
    "            etree.fromstring(label),\n",
    "            encoding=\"unicode\",\n",
    "            pretty_print=False\n",
    "        )\n",
    "\n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": system_message}]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    { \"type\": \"image\", \"image\": pil_image },\n",
    "                    { \"type\": \"text\", \"text\": prompt }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": label\n",
    "                }]\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        raise Exception(f\"{train_type} value error\")\n",
    "\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2815430",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = \"normal\"\n",
    "\n",
    "train_dataset = [format_data(sample, train_type) for sample in SROIE(tasks=[\"kie\"], split=\"train\")]\n",
    "test_dataset = [format_data(sample, train_type) for sample in SROIE(tasks=[\"kie\"], split=\"test\")]\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279092a",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73435b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")\n",
    "\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "    r = 16,           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 16,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_type == \"xml\":\n",
    "    for x in ['company', 'date', 'address', 'total']:\n",
    "        tokenizer.tokenizer.add_tokens([f\"<doc_{x}>\", f\"</doc_{x}>\"])\n",
    "\n",
    "    tokenizer.tokenizer.add_tokens([\"<kie>\", \"</kie>\"])\n",
    "    model.resize_token_embeddings(len(tokenizer.tokenizer))\n",
    "\n",
    "    model.config.pad_token_id = tokenizer.tokenizer.pad_token_id\n",
    "    model.config.decoder_start_token_id = tokenizer.tokenizer.convert_tokens_to_ids(\"<kie>\")\n",
    "    model.config.eos_token_id = tokenizer.tokenizer.convert_tokens_to_ids(\"</kie>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
