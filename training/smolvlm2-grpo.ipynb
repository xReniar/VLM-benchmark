{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5e44cf",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba8e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from dataset import *\n",
    "from PIL import Image\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig, AutoModelForImageTextToText\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    # Delete variables if they exist in the current global scope\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Garbage collection and clearing CUDA memory\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc080f4c",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9001887",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bf4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a highly advanced Vision Language Model (VLM), specialized in extracting visual data.\n",
    "Your task is to extract from the image the requested fields and return the result only in a valid JSON format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8327a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id, use_fast=True, padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ff4b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample):\n",
    "    pil_image = Image.open(sample.image_path)\n",
    "\n",
    "    field_names = set([entity.label for entity in sample.entities])\n",
    "\n",
    "    prompt = \"Extract the following {fields} from the image\" \\\n",
    "        .format(fields = list(field_names))\n",
    "\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"image\": pil_image,\n",
    "        \"answer\": json.dumps(sample.to_json(\"kie\"))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98ea6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'image', 'answer'],\n",
      "    num_rows: 626\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_list([format_data(sample) for sample in SROIE(tasks=[\"kie\"], split=\"train\")])\n",
    "test_dataset = Dataset.from_list([format_data(sample) for sample in SROIE(tasks=[\"kie\"], split=\"test\")])\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79a8ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>System: <end_of_utterance>\n",
      "User:<image>Extract the following ['company', 'address', 'total', 'date'] from the image<end_of_utterance>\n",
      "Assistant:\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=463x1013 at 0x7C4B68B265D0>\n",
      "{\"company\": \"BOOK TA .K (TAMAN DAYA) SDN BHD\", \"date\": \"25/12/2018\", \"address\": \"NO.53 55,57 & 59, JALAN SAGU 18, TAMAN DAYA, 81100 JOHOR BAHRU, JOHOR.\", \"total\": \"9.00\"}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"prompt\"])\n",
    "print(train_dataset[0][\"image\"])\n",
    "print(train_dataset[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d4e0c",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    _attn_implementation=\"eager\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afae6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_LORA = False\n",
    "USE_QLORA = True\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['q_proj', 'v_proj'],\n",
    "    #init_lora_weights=\"gaussian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = prepare_model_for_kbit_training(model)\n",
    "#model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18480dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"result/smolvlm2-grpo\",\n",
    "    learning_rate=1e-5,\n",
    "    remove_unused_columns=False,  # to access the solution column in accuracy_reward\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "    # Parameters that control the data preprocessing\n",
    "    per_device_train_batch_size=2,\n",
    "    max_completion_length=1024,  # default: 256\n",
    "    num_generations=2,  # default: 8\n",
    "    max_prompt_length=2048,\n",
    "    # Parameters related to reporting and saving\n",
    "    report_to=\"none\",\n",
    "    logging_steps=10,\n",
    "    push_to_hub=False,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    use_liger_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7441958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_parsable(completions, **kwargs) -> list[float]:\n",
    "    responses = [completion[0] for completion in completions]\n",
    "    results = []\n",
    "    for response in responses:\n",
    "        try:\n",
    "            json.loads(response)\n",
    "            results.append(2.0)\n",
    "        except json.JSONDecodeError:\n",
    "            results.append(0.0)\n",
    "    return results\n",
    "\n",
    "def all_fields_present(completions, **kwargs) -> list[float]:\n",
    "    labels = {\"address\", \"date\", \"company\", \"total\"}\n",
    "    responses = [completion[0] for completion in completions]\n",
    "    results = []\n",
    "    for response in responses:\n",
    "        try:\n",
    "            response_dict = json.loads(response)\n",
    "            results.append(2.0 if labels.issubset(response_dict.keys()) else 0.0)\n",
    "        except json.JSONDecodeError:\n",
    "            results.append(0.0)\n",
    "    return results\n",
    "\n",
    "def correct_labels(completions, answer, **kwargs) -> list[float]:\n",
    "    labels = {\"address\", \"date\", \"company\", \"total\"}\n",
    "    results = []\n",
    "    for completion, gt in zip(completions, answer):\n",
    "        score = 0.0\n",
    "        try:\n",
    "            completion_dict = json.loads(completion[0])\n",
    "            gt_dict = json.loads(gt)\n",
    "            for label in labels:\n",
    "                pred = completion_dict.get(label, None)\n",
    "                gt_value = gt_dict.get(label, None)\n",
    "\n",
    "                if pred == gt_value and pred is not None:\n",
    "                    score += 1.0\n",
    "                else:\n",
    "                    score -= 2.0\n",
    "            results.append(score)\n",
    "        except json.JSONDecodeError:\n",
    "            results.append(0.0)\n",
    "    return results\n",
    "\n",
    "# TODO: aggiungere funzione per calcolare editdistance sui campi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6affc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOTrainer\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=processor,\n",
    "    reward_funcs=[\n",
    "        json_parsable,\n",
    "        all_fields_present,\n",
    "        correct_labels\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fe07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
