{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7375c62e",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd367240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b49bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a highly advanced Vision Language Model (VLM), specialized in extracting visual data. \n",
    "Your task is to process and extract meaningful insights from images, leveraging multimodal understanding\n",
    "to provide accurate and contextually relevant information.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d58e0",
   "metadata": {},
   "source": [
    "### Read and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d485d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sroie_data(split: str):\n",
    "    root_path = \"../../data/sroie\"\n",
    "    imgs_folder_path = f\"{root_path}/{split}/img\"\n",
    "    labels_folder_path = f\"../../data/sroie/{split}/entities\"\n",
    "\n",
    "    data = []\n",
    "    for label_fn in os.listdir(labels_folder_path):\n",
    "        with open(os.path.join(labels_folder_path, label_fn), \"r\") as f:\n",
    "            json_f: dict = json.load(f)\n",
    "\n",
    "        data.append(dict(\n",
    "            img_path = os.path.join(imgs_folder_path, label_fn.replace(\".txt\", \".jpg\")),\n",
    "            label = json_f\n",
    "        ))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ae853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path': '../../data/sroie/train/img/X51006387847.jpg',\n",
       " 'label': {'company': 'BEMED (SP) SDN. BHD.',\n",
       "  'date': '15/APR/2017',\n",
       "  'address': 'NO.49, JALAN DINAR G U3/G, SUBANG PERDANA, 40150 SHAH ALAM, SELANGOR D.E.',\n",
       "  'total': '635.00'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = read_sroie_data(\"train\")\n",
    "test_dataset = read_sroie_data(\"test\")\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd4ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample: dict):\n",
    "    pil_image = Image.open(sample[\"img_path\"])\n",
    "\n",
    "    field_names = list(sample[\"label\"].keys())\n",
    "    output_format = {field: \"..\" for field in field_names}\n",
    "\n",
    "    prompt = \"Extract the following {fields} from the above document. If a field is not present, return ''. Return the output in a valid JSON format like {output_format}\" \\\n",
    "        .format(\n",
    "            fields = field_names,\n",
    "            output_format = output_format\n",
    "        )\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"image\", \"image\": pil_image },\n",
    "                { \"type\": \"text\", \"text\": prompt }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{ \"type\": \"text\", \"text\": json.dumps(sample[\"label\"])}]\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6073e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [format_data(sample) for sample in train_dataset]\n",
    "test_dataset = [format_data(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145e0382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a highly advanced Vision Language Model (VLM), specialized in extracting visual data. \\nYour task is to process and extract meaningful insights from images, leveraging multimodal understanding\\nto provide accurate and contextually relevant information.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=707x1688>},\n",
       "   {'type': 'text',\n",
       "    'text': \"Extract the following ['company', 'date', 'address', 'total'] from the above document. If a field is not present, return ''. Return the output in a valid JSON format like {'company': '..', 'date': '..', 'address': '..', 'total': '..'}\"}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': '{\"company\": \"BEMED (SP) SDN. BHD.\", \"date\": \"15/APR/2017\", \"address\": \"NO.49, JALAN DINAR G U3/G, SUBANG PERDANA, 40150 SHAH ALAM, SELANGOR D.E.\", \"total\": \"635.00\"}'}]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2eb387",
   "metadata": {},
   "source": [
    "### Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed9847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rainer/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "import torch\n",
    "from transformers import Idefics3ForConditionalGeneration, AutoProcessor\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_id = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33b5d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11,269,248 || all params: 2,257,542,128 || trainable%: 0.4992\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"down_proj\", \"o_proj\", \"k_proj\", \"q_proj\", \"gate_proj\", \"up_proj\", \"v_proj\"],\n",
    "    use_dora=True,\n",
    "    init_lora_weights=\"gaussian\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0f6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_token_id = processor.tokenizer.additional_special_tokens_ids[\n",
    "    processor.tokenizer.additional_special_tokens.index(\"<image>\")\n",
    "]\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    texts = [processor.apply_chat_template(example, tokenize=False) for example in examples]\n",
    "\n",
    "    image_inputs = []\n",
    "    for example in examples:\n",
    "        image = example[1][\"content\"][0][\"image\"]\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        image_inputs.append([image])\n",
    "\n",
    "    batch = processor(text=texts, images=image_inputs, return_tensors=\"pt\", padding=True)\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100  # Mask padding tokens in labels\n",
    "    labels[labels == image_token_id] = -100  # Mask image token IDs in labels\n",
    "\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "# Configure training arguments using SFTConfig\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"training/single_test/smolvlm-sroie\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=50,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    save_total_limit=1,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    bf16=True,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=True,\n",
    "    dataset_text_field=\"\",\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fe4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rainer/venv/lib/python3.11/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/home/rainer/venv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=processor.tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9a724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 28:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.622100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.429700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.818500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.585800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.033000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=0.40667652860283854, metrics={'train_runtime': 1697.907, 'train_samples_per_second': 1.106, 'train_steps_per_second': 0.071, 'total_flos': 3.347114271466656e+16, 'train_loss': 0.40667652860283854})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb504cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=\"training/single_test/smolvlm-sroie/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e131c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU allocated memory: 0.02 GB\n",
      "GPU reserved memory: 2.47 GB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    # Delete variables if they exist in the current global scope\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Garbage collection and clearing CUDA memory\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "clear_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
